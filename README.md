# Robust-Generative-AI-Adversarial-Attack-Defense-on-LLMs-
Robust Generative AI– Adversarial Attack &amp; Defense on LLMs  AI Security– Implement FGSM, PGD, and C&amp;W attacks to manipulate text generation in GPT-2– Apply adversarial training and defensive distillation to enhance model robustness– Compare attack success rates and defense effectiveness
